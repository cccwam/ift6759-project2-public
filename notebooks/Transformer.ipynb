{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rPWV5xl3CUiQ",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyZnw85D9ZvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "from functools import partial\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeC6XIfSBfhk",
        "colab_type": "code",
        "outputId": "faffe7cc-040e-45bb-f8f5-8ec27b8d84fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnyNBKqN9Zve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWEsPNay9sKy",
        "colab_type": "code",
        "outputId": "87c7fb25-be4f-4caa-8ee2-5e1f38e21eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMkVhh59Zvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"..\") # Require to have the utilities packages in path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARTUV5rS97BU",
        "colab_type": "code",
        "outputId": "5a2c30c1-b187-45ce-903e-acac6c74afc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/Colab Notebooks/IFT 6759/Project 2'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/IFT 6759/Project 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmkhWiAX-cOg",
        "colab_type": "code",
        "outputId": "c597ea18-83ac-4884-9b4b-6997475f62c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data\t\t\t\t   training_checkpoints\n",
            "EDA_SeqSeq_ift6759-project2.ipynb  Transformer.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqwB3xqK9Zvt",
        "colab_type": "code",
        "outputId": "5fbbef44-8817-4faa-dd53-2e570e13b9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "data_path = Path(r\"/content/drive/My Drive/Colab Notebooks/IFT 6759/Project 2/Data/\")\n",
        "files = list(data_path.glob(\"*\"))\n",
        "files"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/My Drive/Colab Notebooks/IFT 6759/Project 2/Data/train.lang1'),\n",
              " PosixPath('/content/drive/My Drive/Colab Notebooks/IFT 6759/Project 2/Data/train.lang2'),\n",
              " PosixPath('/content/drive/My Drive/Colab Notebooks/IFT 6759/Project 2/Data/unaligned.en'),\n",
              " PosixPath('/content/drive/My Drive/Colab Notebooks/IFT 6759/Project 2/Data/unaligned.fr')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoZ7BcJL9Zv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(data_path / \"unaligned.en\", 'r') as f:\n",
        "    unaligned_en = [line.rstrip() for line in f] # Remove the \\n\n",
        "    unaligned_en = pd.DataFrame(unaligned_en, columns=[\"text\"])\n",
        "    f.close()\n",
        "    \n",
        "with open(data_path / \"unaligned.fr\", 'r') as f:\n",
        "    unaligned_fr = [line.rstrip() for line in f] # Remove the \\n\n",
        "    unaligned_fr = pd.DataFrame(unaligned_fr, columns=[\"text\"])\n",
        "    f.close()\n",
        "\n",
        "with open(data_path / \"train.lang1\", 'r') as f:\n",
        "    train_lang1_en = [line.rstrip() for line in f] # Remove the \\n\n",
        "    train_lang1_en = pd.DataFrame(train_lang1_en, columns=[\"text\"])\n",
        "    f.close()\n",
        "\n",
        "with open(data_path / \"train.lang2\", 'r') as f:\n",
        "    train_lang2_fr = [line.rstrip() for line in f] # Remove the \\n\n",
        "    train_lang2_fr = pd.DataFrame(train_lang2_fr, columns=[\"text\"])\n",
        "    f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyZTcWbh9Zv7",
        "colab_type": "code",
        "outputId": "98524278-c4e3-4ebc-de7a-892408a7ed53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "max = 0\n",
        "countEntry = 0\n",
        "for index, row in train_lang2_fr.iterrows():\n",
        "    count = row[\"text\"].count('. ')\n",
        "    \n",
        "    if count > 1:\n",
        "        countEntry += 1\n",
        "    if count > max:\n",
        "        max = count\n",
        "        sentence = row[\"text\"]\n",
        "\n",
        "print(countEntry, \"entries have more than 1 sentence\", '\\n')\n",
        "print('One entry has at least', max, 'sentences:')\n",
        "print('\"', sentence, '\"')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68 entries have more than 1 sentence \n",
            "\n",
            "One entry has at least 5 sentences:\n",
            "\" Nous allons devoir réapprendre ce que signifie la construction de toutes ces choses . La rue . Le pâté de maisons . Comment composer un espace public qui soit à la fois grand et petit ? La cour . La place publique . Et comment mettre en valeur cet immobilier . \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ym-3hh09ZwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on: https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7b_0okA9ZwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset():\n",
        "    frText = []\n",
        "    enText = []\n",
        "    for ((indexFr, rowFr), (indexEn, rowEn))  in zip(train_lang2_fr.iterrows(), train_lang1_en.iterrows()):\n",
        "        frText.append(preprocess_sentence(rowFr['text']))\n",
        "        enText.append(preprocess_sentence(rowEn['text']))\n",
        "\n",
        "    return frText, enText\n",
        "  #lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  #word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  #return zip(*word_pairs)\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "    return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset():\n",
        "    # creating cleaned input, output pairs\n",
        "    targ_lang, inp_lang = create_dataset()\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zesqZHqJ9ZwN",
        "colab_type": "code",
        "outputId": "d1f53f01-e7a6-4f63-cb9b-47722ac9e82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "fr, en = create_dataset()\n",
        "print(fr[30])\n",
        "print(en[30])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> en meme temps , je soutiens une politique agricole visant , dans la mesure du possible , a garantir l acces aux marches des pays tiers pour les produits agricoles europeens . <end>\n",
            "<start> at the same time i support an agricultural policy which is orientated as much as possible to ensuring access for eu agricultural products to third country markets <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuC8QhSk9ZwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "#max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ31P5SB9Zwb",
        "colab_type": "code",
        "outputId": "adc524a1-f963-4289-d68f-4a1cbb84d2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8800 8800 2200 2200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMsO7mIh9Zwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdFnIATG9Zwq",
        "colab_type": "code",
        "outputId": "3375fdae-d1c1-4ce7-9752-a58c8aa920c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "2 ----> <start>\n",
            "1202 ----> furthermore\n",
            "60 ----> these\n",
            "6556 ----> websites\n",
            "4 ----> of\n",
            "137 ----> social\n",
            "440 ----> importance\n",
            "45 ----> also\n",
            "5021 ----> encompass\n",
            "6556 ----> websites\n",
            "10 ----> that\n",
            "18 ----> are\n",
            "1545 ----> commercial\n",
            "7 ----> in\n",
            "826 ----> nature\n",
            "3 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "2 ----> <start>\n",
            "21 ----> du\n",
            "321 ----> reste\n",
            "5 ----> ,\n",
            "49 ----> ces\n",
            "2841 ----> sites\n",
            "14 ----> d\n",
            "481 ----> interet\n",
            "525 ----> public\n",
            "3381 ----> contiennent\n",
            "79 ----> aussi\n",
            "12 ----> des\n",
            "2841 ----> sites\n",
            "7 ----> a\n",
            "964 ----> caractere\n",
            "2525 ----> commercial\n",
            "1 ----> .\n",
            "3 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ulfGN6k9Zwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVPKHM7s9Zw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(lang1, lang2):\n",
        "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
        "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
        "\n",
        "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
        "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
        "  \n",
        "  return lang1, lang2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_9p-nY-9ZxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_encode(pt, en):\n",
        "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
        "  result_pt.set_shape([None])\n",
        "  result_en.set_shape([None])\n",
        "\n",
        "  return result_pt, result_en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfSpL59y9ZxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPrigG3o9ZxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQG8bneY9ZxV",
        "colab_type": "code",
        "outputId": "d3feeb58-218f-427d-acf1-77da33d96166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 94]), TensorShape([64, 113]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQXWg4WS9ZxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHVcRDm29Zxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOqt1gRU9Zxl",
        "colab_type": "code",
        "outputId": "53491380-b145-42b6-9a45-c46bae3fa021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "pos_encoding = positional_encoding(50, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 50, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd5xU1fmHn/femdneKywsvSpSRBCx\nYe8aE1s0lhhNYokaE2OKJjHFmKIxicaoMZpmjwb8YbCAoiDFQkfaUndh2b47u9PunfP7494ZZpeF\nHWAXWTzP53Oc2++ZdThz5/ue9/uKUgqNRqPRfD4wPusOaDQajebgoQd9jUaj+RyhB32NRqP5HKEH\nfY1Go/kcoQd9jUaj+RyhB32NRqP5HNGjg76IbBKR5SKyREQ+dLfli8ibIrLOfc3ryT5oNBrNZ4WI\nPCUiO0VkxR72i4j8QUTWi8gyEZmQsO8ad5xcJyLXdFefDsaT/jSl1Dil1ER3/W7gbaXUMOBtd12j\n0WgOR54GztrL/rOBYW67EfgzOA/HwI+BycAk4Mfd9YD8Wcg7FwLPuMvPABd9Bn3QaDSaHkcpNReo\n38shFwJ/Vw4LgFwR6QOcCbyplKpXSjUAb7L3L4+k8XTHRfaCAt4QEQX8RSn1OFCilNru7t8BlHR2\noojciPPNR0Z62tFtKp1xowawZPVmxo0sZ+snKxlwxCCWbGkiIy+Hfi3baWgMUTr+CJat2443LZ0j\nCk2UbbGmxUNbQx1FfUsoU01Ubawh1RAKRw5kY6vQsLMO0+ujsCiXmuo6VDRKVkE+QwrSCG2toL4u\ngK0gN91LZnkJbd5sNlW3UJKfTkEKWDU7aN3ZQosVBSDdNMjITSGlqAA7LYfKT1biEyEjxSQ1Nw1v\nXh7R1CxawjYNrWHaAhZWKIgdCUPUZsKQIqKtzYRb2oi0hgmHo4SiClspooAApoBHhIKyXKxACCto\nYYdswtEoVpT4sbF8awPIPmIkYVsRtqKELZuwFSVqK6dFo6io7TZneWypD/F4EdMLhokyTOcVIarA\nVqCU0681FdsRERBBcF8NY9e6YSBiICJ4U0yUApRCuddw1kE5/yGWKa5UlMysVEQEAQwR3NsgCIbg\n7HO3VVXWxd+1ci7Q4RO5a33IoD5I7PPm/kfctfbrDqvXb0vmMw/AkcP6d7pdZPdty9dsSfq6AEeN\nLO/82p1sW/pp8tcet4frdsaSfbiuc+0B+3Dtzclfd1T76y5ZvRkVqKtVShUlfZEOGNn9FFYwqWNV\noG4lkHjw4+44lyxlwNaE9W3utj1tP2B6etA/XilVKSLFwJsi8mniTqWUcr8QdsP9wz0OcPRRR6jl\n5mTmzXuUnCk3Mff9R/hOxigeeekJCm6ZxXFfOof7Z/+MV2as43vz5tH3gvspPeJoFl6fgd1Ux0nv\nFvDRi//i8nvv4P7wa/z0K08wPNPHtS89wVcWpfLKI0+TWTqQa288lz8/9G8iwVZOuPpSXrrySDbe\n9hX+9c/lNEWiXDyqlOP++B2Wlp3C1Q+9x51XjOXqwSa1j/2ChX+ay5yaNgAm5KQy+fxhDLnxGlqO\nPJsfZo+mb4qHKQNzGHHRUfT90pdoHXkK725u4rkPt7JsWTU7N6zFv2MTVtDPohdvpG3hG1S+u4Sq\nxZVs3tLMprYI9WGbcFRhCuR4TQp9JtfcdSG1yzZQt6aWhopGKv1hakI2DRGbgB3Fdv+6PkM4+6U3\n2NIUZFNtK5vrWqmqa6O1OURbU4hgW5hQSyPhtiasgB8r2Mq875RjFpRi5hVDRi7RlCyiablEzBTa\nIlFaI1EClqI5ZHHK5T/B9PowPD4MjxfD48NMScP0+OLLhseHx+el37ACrHAUK2JjRWxsK4oViRK1\noth2FNuKErWj2JZF1Aoz5eQR+DwGPo/pvJoGKR7D3da+3fPjp1FR2/kMuV9ezrLzGnVfAR792w8w\nBEwRDBFMw/lS6bguAgbC0Rfc1e5ae2PGGw8Buwb52E9qcTcYCSP0gGm3dnm9RN5+90+dDvBGJxuL\nT7gl6eu++/4j7dY7u0eM/Kk3J31dgPfnPZr0sbnH3ZT0sfM6XDdnyk1Elvwt+W+NzrCCeEZckNSh\nkSV/CyZI172CHpV3lFKV7utO4BUcbara/fmC+7qzJ/ug0Wg0+4QIYphJtW6gEkj8WdjP3ban7QdM\njw36IpIhIlmxZeAMYAUwHYhFoq8B/ttTfdBoNJp9R9xfrF23bmA6cLU7i+dYoMmVv2cBZ4hInhvA\nPcPddsD0pLxTArzi/pz1AP9WSv1PRBYDL4jI9cBm4NIe7INGo9HsG+6TfvdcSp4FTgYKRWQbzowc\nL4BS6jFgJnAOsB5oA65z99WLyM+Axe6l7lNK7S0gnDQ9NugrpSqAsZ1srwNO3ZdrrdoZZsp3r+ad\nkZOZcuvDLDjmRC4dU8yl851v2unn53HbTav50S/O5ew/LyTYVMvf7ziBOWefQeTl11g281eUTzmP\nB84czNsjniVgK07/+hQWpo7m3ddfRkVtRp94DC/NXENbXRUDjjufu04bTvTNJ1k6fS01IZsJuamM\nunQi1rhz+ef/1jF+fB/OGFpAdNG/2fTmSpY3hQhHFf3TvAwemkfZieNg2GRW1QTI9BgMyvBSPKaY\nwolHoMrHsKU5zEdbG9m4rZnm2gaCDdVYQT8A4YqVNK7dSuPGBhq3+6kJ2fitKOGoI9D7DCHDNMj3\nmbRW1tK2009bbYCmoIXfitJqO8fG9HxTnNYQiNDQFqauNUydP0woYBEOWIRDFpFgG3Y4gB0KELXC\nqKiNkZ6FkZqB+NKIelJRvnSUJ4WwpZyAcFQRtqOErChixn7yGohhYnh9GO5PYMPjQwwT0+NBRLBj\n2r0dRUWdQLKKKqLKeVVKEY2quHZuGoJpGM6riLveSUuIkqpodO+fT9u9dpJ6/q7rdq3n7wudBXb3\nh870fDmAi3dTt3olAojZPYO+UuqKLvYroNMAiVLqKeCpbulIAj0dyNVoNJrehQhGNz3pH4roQV+j\n0Wg60F3yzqGIHvQ1Go0mkW7U9A9F9KCv0Wg0CQiC4fF+1t3oMXqFy2aopZG3TwnyxrZmZp9r8srq\nGo5dOJfXHnmSn//set468csck5dG7bW/ZOFzLzDp0ksYPe8RXlldw+2PfICybe65/hhqH7idmZXN\nnN0/mz7f/infe3EZtWsXU3zEVO654AgqP55DRlF/zjltKMemN7Ly8ddY3BAkx2swYUoZRRdfyVsb\nG3l38VYun9ifstaNVL4+m7UraqgOWaSZwuhsH/2OG0jG5FPYYeQyb3M9JSke+g/MpXTiUFLHTKHB\nV8CS7S18vLmB+u0ttO7cQri1CQDTl0Zw0wYa11fRvK2ZmpBNs+UkWoETxM30GOR43UDujjr81a20\n1QdoikTjAV87IfPUFMFnCPXBCDubQ9T5QwQDEcKBCOGQ5SRIhQJYYSeIG7Ui2JEwRkY2RkYWUV8a\nUW8aypNCROEEcKMKy4a2iE3QisaDtrEgriQGcc1YMFcwPQYqihOwjSpsO+oGbVU8OUu5QVwVtVG2\nHQ/U+kwnASuWmNUxkGuItAu07i0xCzoPfu6JfYmJxu6XTGLW/vB5DrIeFA7uPP2Djn7S12g0mg70\n1gE9GfSgr9FoNImIdNuUzUMRPehrNBpNAsLh/aTfKzT9/uV9+OVxt3DvHy/jwYnX893vnsQxP3yT\nPuNP4/rqV3m1ooEvT/8pF/98NukFfXntm5N57uZ/MjwzhY3vT+eocy/gqvwaZjz8Hvk+kxPvv4Rn\nNipWvv0evowcTj/rSE5Or8UOBxg8eQq3nTCQxmf/xIJ52/BbUY7NT2PUV6ZRlX8kT83fRNXqT5k2\nMIfA3FfY+NYG1vrD2AoGpvvoP6GUPtOOxRpwNB9VtTBn9U6GZnrpM6EPOePGEelzBOsbgny4uYGq\nrU207NxO2N9A1AojhokvI4eGtVtp2txMfV0gnpiVaJwWS8xKz0+jZbuftroA9WGbpohN0NXbExOz\nfIaQZhrU+8PUt4ZpjCVmhWwiIQsr4McOB4hGXD0/lpyVkYXyZaC86eBNJepJIRhLzLIVQStK0IrS\nFrHbGa2JYWIkJGUZHh+GIZimgWka8cQs24qiosS1/Li2H9P0bUfXjxmtmYbgSdDw2+n6Ipiu2N3d\niVkSv27yiVl70vM7O+ZA0YlZ3YwYmB5fUq03op/0NRqNJhE5vJ/09aCv0Wg0CQh6nr5Go9F8rjic\nB/1eoelnN1RSmurh0eFfBWDZNQ+wbs4rzP7VOTx85aNcfWI5D1sT2Dx/Bt++8xKqbr+SxQ1Brrj3\nLLL7DefpGybxyc3fZWlTkAtPGUjrOXfwu2eX4q/exMBjp/Gj04ay/c+/pWDoBL55/ijKKz9g6ZPv\ns7olRP80L0d+YRS+067m1TU1rPxkO83b1pK27j02/PcDlm1poj5sk+8zGVmaQf+TR+MbP431zYp3\n1tVSWdFA3zHFlE4ejWf0sVSGTD7e3szSTfXUV/sJNOyIz9H3pGWSklNI4/pqmrc1syMYm6O/y2gt\n0+Po+TmpHjJK0mmtbqWlKURTJEowqgjYu4zZYuf4DCHVkPgc/VDAIhSIEAlZRIJB7LAzR9925+nH\ntHRJy0L50lDeFKLeNEJWNK7nh21FW8SmLRIlZEfjRmsx47W4nu/O2TdMA8NjIIYQtZyCKUopp2BK\nB6O1mOFbrHVptObO0TcMiev5Xc3Rj7EnPb8jyc6t70r3j13nUNXzP2sOia7refoajUbzeULLOxqN\nRvO5QUQwvL1zZk4y6EFfo9FoEtGGaxqNRvP5Qg/6nzE7qv1ct+NDsi/4Lf5Fj1N4+5+ZdsP1tN56\nGa12lAmvv865F/2aISdfxN19qvjB00v44sgCgl/9BZcPqqB87mP89K2NHJOXyvgHf8K1M1azaf4s\ncspHccsXj6Rs9f8x/YkFjPvp9Vx1ZCEbbr+D9ysaMEU4bkQ+A666lCWBLJ599xNq1nxE1Aqzc8Yr\nVMzdwtZABJ8hDM/0UT61H3knnExj7hDeX1XDh2tqaKisos/EgWSMm0IgfzArNjUxf10ttZUttNZs\nIdTS4CRCeXz40rNJLyij8aMmqlvCNER2BXFNgUyPQbYbyM0oySCzJIP6dQ3Uh50ErsTqWtA+iJtm\nGtS3hmhpDRMKRggHLCIha5fRmpuYFU0IoCqfY7KmvOlYGITtqNucIG7IjhKybKdyVoLBmtkhiGt6\nDEyP4QRKPUY8Ecu2VNx4LZaYlWi01i6Q2yExq12ClpuYFauctbcgbiwxCzoP2MZITMza3yBudxut\nHQx6QRcPCkZv+J+1n/SK2TsajUZzsBARxEiuJXm9s0RkjYisF5G7O9n/kIgscdtaEWlM2Gcn7Jve\nHe+vVzzpazQazcHENLvneVhETOAR4HRgG7BYRKYrpVbFjlFK3ZFw/K3A+IRLBJRS47qlMy76SV+j\n0WgSEbrzSX8SsF4pVaGUCgPPARfu5fgrgGe74V3skV4x6JcUpDH+NyspO/pUTp0lmClpvH4aPPLc\nKr7zyBWc9Nv5WMFWXv3+yfzvzG/hM4RTXvw1lz22kAdPKWbmLc8QjirO+e6pvCUjePOVeQCMPX0K\n143MYNn9TzC3to2fnTsa+78Pseg/q9kRtJiQm8qY646nbex5PLFgMxs/WUNbXRVpeaWsn7GUpU0h\nAraib6qHYaMK6X/aRBg5lU92tPLGyh1Ub2nEX72JoinjiQ4az4aGEIs2N7BhUyNN1bUEG6qxgn4A\nfBk5pOWVkpWfSeN2PzuCVjuNPs004kZrOfmpZBank1GaS1PQoikSpdWO7ma0lmi2lukR6mJGawGL\ncMgiEmzDDgewQ4F4QlQ0sisxKupNR/nSiXpTCcWSsqKKsB0l5BqtxV5jGr5htE/OMj0eTNNJynKS\ns5wCKlHb1fLdBK1YYlaing+OTm6K7LFwSiypynATtPZGop4Pe07Miun5iexr0tDe/mElXutA/gEe\nbkZrh0RiFjGXzW4b9MuArQnr29xtu99XZAAwCJidsDlVRD4UkQUictF+vqV2aHlHo9Fo2tH1A0QC\nhSLyYcL640qpx/fzxpcDLymlEp9OBiilKkVkMDBbRJYrpTbs5/UBPehrNBpNe1x5J0lqlVIT97K/\nEuifsN7P3dYZlwM3J25QSlW6rxUi8g6O3n9Ag36vkHc0Go3mYNKN8s5iYJiIDBIRH87AvtssHBEZ\nCeQBHyRsyxORFHe5EJgKrOp47r7SKwb9QMkA1r/7GssfPIf5f3+G6X+8gScnX88XRxbw+sRv8skr\nz3LFLVeR8cidzNjWzFdvOY7H/UNY8t//sP62G3hrZytfOLoPObf/jrv//hH1FUspn3Q6D3/xKBqf\n+BlvvbsFgPHhtXz0+5ksbghSmuph4lmDyf3i1/jPp7W898EWGjatwPD4yB86gZVr6tkRtMjxGozJ\nT2PAqSNJn3IOmyMZvL22hg3r62jcupZgUw2+o05kB9ks3NbEB+tqqdvhzNGPG62lOkZrGYWl5Bal\nUxmwaLaiuxVDz/eZFKZ4yCjOILNvFpllRdSHbVrt6G5Ga6Y4Wn6qYZDpcVpba5hwIOKarYWxAv7d\niqHH9HzANVtL21U0pZ3R2q4WiNi7jNU8Pqd53VdXzzdNI15IJT5P325vvJZospbYErV8Xwdt30iY\no29K8kZrKmp3abR2IHP0d11jz3P0u1vP780cKno+OH0xPZJU6wqllAXcAswCVgMvKKVWish9InJB\nwqGXA88ppVTCtlHAhyKyFJgD/Cpx1s/+ouUdjUaj6UB3OpUqpWYCMztsu7fD+k86OW8+MKbbOuKi\nB32NRqNJQNzZYIcretDXaDSaDuxDILfXoQd9jUaj6cDhPOj3ikDups07+MEv7+CdkZOZctXVFPzy\nBja1RThpwSxu+dE/KJ9yHo9NtPjLA7O5cEAOafc8xs8eeh1fRg7PvrCKsTmpHPfYvdw+41PWzH6d\n7H7Duenyoxi+ZTYLfvc2m9oiTC1Io+Kh3/LOsp0AnDgsn2E3fJlV0pen3t7AjpUfYYcDZPcbzpCj\nSlnrD2EKDM/0MWjaAIpPO5Xm4tG8u6me91ZUU7NxG221VaioTaB4BMuqW3l/XQ07tzXTvH0TwaZa\nolYYw+MjJSuP9IIycoszGNgni1rXQM1WToJVmilkewyKUkwyStLJ6ptJZlkRGWVFNEU6C+I656S6\nAeBMj5CZ4iHYFiHkGq3Fgrh2KIAdDmJ3qFYFoLzpRMRDyIoSdKtmBSNR2iK7ErOCdpRA2HYTsXY3\nWosFb02PgWE6CVq2pZwA7h6M1oB2/ejMaC1eTUuIJ2bFfpJ3FlRNTMzaW3WrRKO1jtv2xL4EcXsy\nYHmwKmbtwxz23ok47zGZ1hvRT/oajUaTgOA8nByu6EFfo9FoEpHD21pZD/oajUbTgd5cXL4resVv\nGG96Fjetfpw3tjUz+2x46ImPufuxK5n6+48JNdXy+k9OZ+bx12GKcMbMh7nojx9Qu3YxJ15+Pn4r\nysU/OJ0308Yz/fl3UVGbo88+gW8ekcnSn/6Rt3a20j/Ny+TrjuH9Z5dT5Rqtjb3xJAITv8DDcyuo\n+PhTWmu2kpZXSv8jR/OVKQMI2Ir+aV5GjSlmwNmTYcwpfLi9ldeWbWf7xnr81Zuwgn4Mj4/1DSHm\nVdSxtqKBhsodnRqtZRfmUFSSyVH9c3czWsv2mHGjtaw+mWSU5pJZVoSnqMxNzGpvtBYrnhIzWsvx\nmqRkpxAOWE5iVoLRmh0O7ma0FiNmtBZMMFqLJWTFjNYCYafF9fwORmuGx4gbrcUKqezJaC2xD3HT\ntw7JWfEkLdOI6/hew3C0/Q7/UGOJWXvS87syWjOkezX4Q9Vo7bPmUOu6Y7iWXOuN9Hi3RcQUkU9E\n5DV3fZCILHQLCjzvpiZrNBrNoUFsckASrTdyML6rbsNJP47xAPCQUmoo0ABcfxD6oNFoNEkiGKaR\nVOuN9GivRaQfcC7wpLsuwCnAS+4hzwDd4hGt0Wg03YHoJ/0D4vfAXUDUXS8AGl0TIth7QYEb3eIB\nH5akBPnx7S/z40ev4MFJN3LlsWX8feR1LH31OW77/vXIfdfz2vYWvn7vmfxqe1+W/PclBp94IS9c\nPZ7Lpw3E880H+O6Ti6mvWMrgqWfxyCVHUfPwPcycsxlT4LSp/eh/07dZ3BCgf5qXY78wguxLbuLZ\nFTt5f95mGjatwPSlUTRyImccW87ZQ/PJ95mMK81k0FljSD3ufNYHU5m5qpoNa+to3PIpwaYaxDBJ\nyyvhg62NLFhXS21Vs1sMvR5wjNZS80rIKu5DfkkGR5blMKIoczejtaIUk6J0LxnFGWT1yyGrvISU\n0lI8peW7zdGPafkZpmOyluM18aV7Scn2EQpECAcCWAE/kaDfNVoL72a0FsOZn++YrIUsRUtod6M1\nf9CiLWzv1WjN9LivrsafrNFarEh7MkZrhtHecG1PRmuJdGW0Ftvccd5+IgdqtNYdWvzB1PO7e276\noabnx+jOGrmHGj026IvIecBOpdRH+3O+UupxpdREpdTEwoKCbu6dRqPRdI4InScDdtJ6Iz05ZXMq\ncIGInAOkAtnAw0CuiHjcp/29FRTQaDSaz4TeOqAnQ4896Sulvq+U6qeUGojjFT1bKXUlji/0l9zD\nrgH+21N90Gg0mn1FSO4pv7d+MXwWyVnfA54TkZ8DnwB//Qz6oNFoNJ0iAj5tw3BgKKXeAd5xlyuA\nSftyfu2KNVwyYTyPDLkWHy8x7H9vcM75P2bMeZdyT9rH3P3YYq48toz6a+/nwev/SGbpQJ6643gq\nv3M1E5/8Pef/awnr332NgqET+PG1R9Nv8T958Y9zqQpanN8vm3Hfv475dj98hnDyhFKG3vwN5vmz\neGrWx2xf/gF2OEDh8GMYO7GMqyb0o7B6CUdmpzDkjCEUnXEONblDeXNFNfOX76B240ba6hyjtZSs\nfDJLBvHWqmp2bG6keXsFwaZaJzjpSyM1p5CMonLySjIZ0T+XMWU5DM1PZ6ZrtJbpMcjzmhSlmGT1\nzSS7n1MtK6NvMZ6Scsgp3i2I6zN2Ga3leA3SfCapeamk5aUSCkR2VcuKhB2jtYgTzO0skOtUyooS\nsnavltWakJgViNjtgrimxzFYixmtiUg8Scs0jd2M1qJWGGW3D+LCLtO1dklZHiMevPUmJGglGmAl\nBnH3x2gt8QFuf4zW4ud2YrTW3UHcZO/fPdf7nARxxTH5O1zRNgwajUaTgHB4a/p60NdoNJpEpPfq\n9clw+ApXGo1Gsx84T/pGUi2p64mcJSJrXOuZuzvZf62I1IjIErd9LWHfNSKyzm3XdMf76xVP+raC\nAf97g7PPvRv/oscZcudrZBT1Z/73pvBY30mMykph8uuvMOae2bTVVXHXfbcy7qO/8eu/fkz2ZZnM\nf+lFfBk5XPrlk/hi9k7evftvzKsLMDYnlWO/dyY14y7m3r9/zJ3FmYy/40K29p/KAy8tZ+OHHxNs\nqiGrzxAGTxjJ144byHCjjtrpLzDi2DL6n38q1uhTmLuugekfVbK9Yif+6k3Y4QCe1EwySwZSWF5C\nxYZ6mqoqaaurwg4HEMPEl5FDRlE5uUUZlPXN4qj+OYwszKA0w/lfkqjn5xRnkN0vi+zyYrLKSzBL\nyjGKy7GzSnYzWktzk7IyPQbZXpM0V89PzUvFCvixwwH3tfPCKYmELOUYrlnRBD0/SshyCqfEErNi\nRVQMj29X0ZSY2ZopcX3fMATTI9hWlKgdxbaseOGUzhKzYrQzXBPBa+zS8WNGa6bs/pN8b3q+Eyto\nb7S2p8IpHXX+feWzKJxyqOv5hzrd9aQvIibwCHA6TjLqYhGZrpRa1eHQ55VSt3Q4Nx/4MTARUMBH\n7rkNB9In/aSv0Wg0CRiyKwO8q5YEk4D1SqkKpVQYeA64MMmunAm8qZSqdwf6N4Gz9utNJaAHfY1G\no+mAM0Os6wYUxuxi3HZjh0uVAVsT1vdkPfNFEVkmIi+JSP99PHef6BXyjkaj0RwspBOpcC/UKqUm\nHuAtZwDPKqVCIvJ1HCPKUw7wmnukVzzplx4xmClff4qyo0/l1FlC9fK5zHjoauYddzpVwQjXvnYf\nZz79KRvfn87kyy/lx8P8vHDjX2mK2Pzu0bcJNFQz/vyzeeDMway46/vMXF1LaaqH0686isxrf8Qv\nZm9g9XufcPStJ8I5t/D79zax7L3VNG9bS2pOEf2OGs9XTh7MtPJMwrP/xbpXP2bYxVMwJp3P4u1t\nvLqkki1ramnasopQSz2Gx0d6YV9y+5UzeEg+dZW1+Ks3EWltApzCKekFfckpKaS4LJsJA/IYXZRJ\nv2wfmaF6txC6o+cX5KWS2TeTrH55ZJWX4CsbgLfvQKKZhYR8WUCini9kmM78/ByvQUqOj1RXz0/N\ny8AK+okEdhmtdVY4JYYYJkHbKYjuD1v43fn4bREbf8japedHbAJhC8Prw/R4HMvZ2Jx8j7Sbr2+Y\njmVtYuGUvRmtxfT+uOFawrz8jkZrsXn6nRVO2RPJFE7ZV6O1xOt0PP9gGa31hoknh3qIoBszciuB\n/gnru1nPKKXqlFIhd/VJ4Ohkz90fesWgr9FoNAeLWHJWMi0JFgPD3OJRPhxLmunt7yd9ElYvYFf9\nkVnAGSKSJyJ5wBnutgNCyzsajUaTgCDdZsOglLJE5BacwdoEnlJKrRSR+4APlVLTgW+JyAWABdQD\n17rn1ovIz3C+OADuU0rVH2if9KCv0Wg0Ceyjpt8lSqmZwMwO2+5NWP4+8P09nPsU8FS3dQY96Gs0\nGk07Dncbhl6h6a+qiRBqqWf5g+cw/+/PcNd9t5J7/w28sHwn3/75ufyqbSwf/OvfDD7xQv73jUm8\nc9FNLKgPcMVpg6j5dAHDpl3I3645mtoHbue/M9ZhK8U5J5Uz6Hv38MTyembOXEl9xVIKr/8uTy3Z\nzsy31lO7djGmL43i0ZM5/6RBfGFkITL/BdY+P5dlK2rIOOWLrLeyeWlpFctX7KR+4yoCDdXxalm5\n/YfTd1Ae00YV01K1vl21rLSCvmSX9qOgTyYTBuQxpk82g3JTyTdCeOo3k+MmZRWle8nul0VOeS7Z\nA/uQ2r8/3r4DsbNLsTOLaBIaYMMAACAASURBVAg6wcTOqmWlZ6eQmusmZuWmkZKbRSToJGfFjNb2\nFsQVw+y0WlZrePcgbrxylplotLaHJC2P0a5aVmIwubMgbqLhWmK1rFiClje23Q3odkZniVm7vee9\nVMsyhHa2a10FcROvGWNPQdz9HVt0taweRBdR0Wg0ms8PMT/9wxU96Gs0Gk0H9KCv0Wg0nxOMw7yI\nSq94Z8HmRt548nbeGTmZKVddzV31L/H7v3zINy4ewfIv3Mvv7n+G/MFj+e8Pp7Huq1/kheU7uWhw\nHhOe+jOlY6fx+69PpuTNh5nx8HtUBS3OGZbP+J/dzuv+Yv784gqql8/Fm5HD67WpPDljNVVL56Ki\nNoXDj+H44wdyzdH9yN80j00vzGDF+1tZ6w9RmTWE6aurmbekiup1a2it2RovnJLdbwSlA/I45YgS\npvTLI9BQHS+ckpZXQlbJAArLshkzMJ+x/XIYUZhOn3QDT90mwhUrKfSZlKZ6HD2/XzbZg/qQUV6G\nt89AVF5folnFNISiNAbteOGUXXq+QUaap53RWlpBDqkF2dihAFErstfCKTE9XwwzruO3hHcVTvEH\nLcdsLWThD0bihmsxvd7jNXcZrCUUTolr/YbssXBKRz0/hs9j4DWMPRZOMY32RVS6MlqLv9e9FE5J\n1PP3dH6y6MIpuzjk9XzQmr5Go9F8nhDivjqHJXrQ12g0mg4czlbSetDXaDSaBAT2OP33cKBXDPr9\n+pdi3Hwpb2xrZvbZ8INxT3HB0Hzyn3iZs274K2IYPHLPRWQ8ciePvbiaY/PTOO2l+/nJ0ig//OaJ\nnLhzDv93x7MsbQpyWnEGxz9wDSv7nshPn1zEpkWzEcOk/JhpPDB9FZsWzSfS2kT+4LGMnjKMW08Y\nzODWdVQ+9yxrZqxlRXOIgK14fV0dMxZuZfvazfh3bCJqhfFm5JBdNpzSgUUcN7qY4wfmM6IghagV\nxvD4SM0pJLN0EPl9shhWnsuEAbkcUZxJWaYXb916rI0raF2/ztHzy7LIHZhD9qBSsgf2wdN3EFLY\nDyurhCbLoCFos70lFDdZi+n5OameuMlaemE6qa6en1qQ48zR30vhlEQ9XwwTf9jGH7Z2Ga0FnTn6\nLSErPj8/ELaxIraj5Scaq8U0/IQ5+x7Xgzym50e7KOISL4yeYK5miOA1pV3hlMTlZPV82F3P78x8\nDZxBwBDZJz2/swfFjnp+d8/RP9T1/F6D+1k7XOkVg75Go9EcLATwJlkKsTeiB32NRqNJQMs7Go1G\n83nCnRJ8uKIHfY1Go0kgFsM5XOkVwlVu03aeeG0dP370Ch6cdCOjslI4+eM5TPvBLJqrNvDDe67l\n9KVP8JcHZtM31ctlf/smf7dH85fHXuOGwmre/doDzKpuZUJuKqf97EJ2Tv0qtz23hLXvvoMV8FM6\ndhpXnTeST+d+QFtdFVl9hjDs2KP49qnDGOupofbFv7HqhSUsbgjQFIlSlGLy3Aeb2fppJY1bV2MF\n/XhSM8nuM4SSwWVMGF3MtGGFHFmcTtrONYhhOkHckkEUluUzeEAukwfnM7Ykm/5ZXlIbt2BvWU1g\n/ac0rttKfkkGuQOyyRlYQs6QMrz9hmKWDsLO6UOrpNIQsqlqCVHZEiQtIYib53OSstIL00kvSCO1\nICsexPXk5mO71bJiAdTOiAVxTa+PlpBTMavFNVmLG62F7fhrOGxjW9HdjdViCVkep1qWJ6GYdMek\nrD0ZrcXaLnM1I14lKzFRa1flrF3vI1mTtcTlWBC3XXD3wD66e/wH1v1B1+6+XvcPer1pHHWM/bpu\nvRH9pK/RaDQJiPtAcbiiB32NRqNJ4HCXd/Sgr9FoNB3ordJNMvSK3zDbd7TwvTtP4JEh1wJw1dKX\nmPTzeWxb/D+uuuOrfMuez59u/AemCDc8+CXeGX4Z9z70Jk1bVvPBNXfy6po6hmf6OP+uU7Gv+BG3\nvLyc5W/OJdCwg+LRU7ng7BHcPLkfLds3kFHUn6HHTuL2s0Ywrcii5dW/svKfC1lU1UJNyCbHazAh\nN5WNK7bTuGkFkdYmTF8amaUDKR4ymDGjijljZDHj+2SS07SR8Ip5pOYUkVkyiIL+xfQfkMtxwwoZ\n3yebgbk+MlqrUVtXE1y7goa1W2lYV0Pe4FxyBhWTM7QMX7/BePoOxs4ppc2TSV3AZkdLmO0tIbY1\nBMj2GOT7TPJ9pmOuVphGemEaaYVZpBbkkF6chzcvDyO7YK96fmJSlun1xZOz2iVlBS38IYuWYCSu\n51sRGysSxfAYeLztTdc8XiNeWCWm56d4jF2Ga13o+TES9XyPaSRo+Lv0fK+5yy8lGT0/fm3pWs83\nRPZLj+7uwil7vE8vGKB604OzsMvAr6uW1PVEzhKRNSKyXkTu7mT/t0VklYgsE5G3RWRAwj5bRJa4\nbXrHc/cH/aSv0Wg0iXRjjVwRMYFHgNOBbcBiEZmulFqVcNgnwESlVJuIfBP4NXCZuy+glBrXLZ1x\n6RVP+hqNRnOwcDT95FoSTALWK6UqlFJh4DngwsQDlFJzlFJt7uoCoF83vp3d0IO+RqPRJBCzYUim\nAYUi8mFCu7HD5cqArQnr29xte+J64PWE9VT3ugtE5KLueH+9Qt4pzkvl/S/fz8+/eT/+RY9z/N93\nsHrWS5z5zRt4dMROnjjplzREbG7/6dmsO+u7fPO+N9i5ah5DTr6I5/9wG31TvVx80xRybv8dX395\nBR/MeBd/9SYKhx/DGeeO5funDCZl9pOk5ZUyePIUbjp3JOcNSCX48u9Z/vRcPljfQFXQItPj6PnD\nTh1IQ8VSgk01GB6fq+cPZ+TIQs46ooRj+mZR2FaFtWIetQs+JqNoInllpfQtz2XqsEIm9MlhcG4K\n2cFaZNsqguuXUf/pZurX7KBhYyNDzhpB3vD+pA4Ygrd8OFZOXwIpedS2Wezwh6lsDrKloY3NdW0c\n53Xm6KfnO1p+emE6aQWZpBXlOXp+bi5GbjFmXlGXhdANjw8xY8te/GHLLZayS88PhJ0iKoGgFdfz\nrYjtmKolzM83TInr+Wk+M67n+zxmUvPzIWa4Fu1Uz/cmLDtF0WWfTNFU1G5XCB32rOfvD8nq+Qec\nB9ADWvnhPHMlKQT2YcZmrVJqYrfcVuQqYCJwUsLmAUqpShEZDMwWkeVKqQ0Hcp8ee9IXkVQRWSQi\nS0VkpYj81N0+SEQWukGN50XE11N90Gg0mn0lNmWzmwK5lUD/hPV+7rb29xQ5DfghcIFSKhTbrpSq\ndF8rgHeA8fv9xlx6Ut4JAacopcYC44CzRORY4AHgIaXUUKAB5+eMRqPRHCKIa+fddUuCxcAw92HX\nB1wOtJuFIyLjgb/gDPg7E7bniUiKu1wITAUSA8D7RY8N+srB76563aaAU4CX3O3PAN2iU2k0Gk13\n0J1P+kopC7gFmAWsBl5QSq0UkftE5AL3sN8AmcCLHaZmjgI+FJGlwBzgVx1m/ewXParpu9OVPgKG\n4kxb2gA0un8I2EtQww2I3AjQJz21J7up0Wg0cRwbhu6LayilZgIzO2y7N2H5tD2cNx8Y020dcenR\n2TtKKdudY9oPZ+rSyH0493Gl1ESl1MSMQcP5xrd+R9nRp3LqLOGjF//F1Guu5b+nmvzzlNtY6w9x\n850nUX/t/VzxqzlUfTSLAcedz+O3TiXfZ3LZV8fT554/cOf/rWHWy3Np3raW/MFjOfncifz4jGHk\nfvAvPv71iww69nhuPG8Ul4/Mxfq/R1n+1znMX1HD1kCETI/B2JwURp48gMEXTyPQsCMhiDuSEaOL\nuHBsX47rn0NJuBpr+VxqP1hM1cIK8vv3p+9AJ4h7dFkOQ/NTyY00INtWEVr7CfUrNtKwZjsNFY3U\n1AbIG15O6kAniGvn9CWUXkBdwGJna5itTQG2NAbYXNfGtvo28n0mmXmppBemkVGSQUZxFmlFeaQV\n5OAryMfMK8bMKcDIyidqhXf7O3cM4poeH4bHi+Hx4Q9ZNLVF2gVxW4IWoYSkLCtiE7Wi8cpZHp+J\nYUo8QSsxKcvnMXdVzkoyiAvEq2btKYjrjVXP6uTTvKeKXLAriBuroBX/m7ivsSe5A4lrfpZB3P25\n/uc+iOsiklzrjRyU2TtKqUYRmQNMAXJFxOM+7Xca1NBoNJrPEuOAv5IPXXpy9k6RiOS6y2k4GWmr\ncbSpL7mHXQP8t6f6oNFoNPuKoJ/095c+wDOurm/gBDBeE5FVwHMi8nOc9OO/9mAfNBqNZp/pDX5G\n+0uPDfpKqWV0MqfUnW86aV+uVbFpB+VfnsryB88hZ8pNTLnqat66KJt/TbyCpU1BvnX78bTd/jAX\n/3w2Wz54jfIp5/GXO45n4qrnKL12HP3vf5w7Z23mlWffoXHTCnIHHslJ50/h/nNHUfzh83x8/z95\n+6PtfP23o7lmTCH2jD+w5JFZzF9Szaa2CGmmMDYnhTEnlTPskml4T/gShudXZJYOpGjoaIaNLuKi\ncWVMLc+lT6SG6Iq51M5bQNXCDVSvqKH0wlxOHFHElAF5jCpMp8BqwKhcRXjtJ9Qt20Dd6krq1jWw\nc2crO4IWaUOG4Rs4EjuvP6GMonhS1pamIFsaA1TUtLK5tpXmxiCZealkFGc4mr6r56cX55FSXOjo\n+XnFGDmFRNNydvu77k3PN7y+dnq+PxiJ6/nhkIUViRK1nGZFoqSmezvV89N8Zjs932ca+6Tnq6jt\nGq5Jl3p+Rz16b3p+jEQ935A96/n785NY6/m9lF78FJ8MSX2WReRiEVknIk0i0iwiLSLS3NOd02g0\nmoONdO88/UOOZJ/0fw2cr5Ra3ZOd0Wg0mkMBLe9AtR7wNRrN54XDeMxPetD/UESeB17FsVcAQCn1\nnx7plUaj0XxG6HKJDtlAG3BGwjYFHJRB35OWyeqHz2XOyMlMufVh5nwhk78f7QRxb7vzRNru+CMX\n3vc2m+fPoHzKefz1zhOZtPLfTP/aY1y0YT63u0Hc+oql5A8ey0nnT+E3F4x2gri/eIa3FlVRFbS4\n66giojP+wCd/nMl7n+yIB3En5KZy1CkDGXbZqXhPvJRPrZx4EHf0mBIuGlfGiQNy6WvVEF3+DjXv\nzady/nqqV9SwpiXMtFHFuwVxQ6sWdRrErQ3b8SBuMKOIGjeIu6khsFsQt605REZxRrukrD0FcTsG\ncvcWxDVT0jA9vi6DuLEELduKJh3E9XmMfQriAkkHcRM1Vh3E1RwIh/GYn9ygr5S6rqc7otFoNIcK\nh3OhkWRn7/QTkVdEZKfbXhaRHq3uotFoNJ8F4pZLTKb1RpL9Qvsbjh1oX7fNcLdpNBrNYYfOyIUi\npVTiIP+0iNzeEx3qjCP7ZfH6oInMrW1j9tnw5NFXsdYf5jv3nEHN1x7gC/e+QeXimQw+8UL+ceeJ\nHPHBY7x089+ZVxfg9RkV/N/zb9O0ZTUFQydw5heO4xdnjyB/3tMs/sW/eXtJNTuCFgPTvURe+g2f\nPPIG7y3fZbI2ITeVMacNZOhlp2OeeBmrgxm8sLSKkmFHcORRJXxhfBnH98+hNLQda+kcat5fyLb5\n69mxqpb1/gjVIYvzB+YzojCNgnCdUylr1SJql22gblUV9evrqakNUBmwaIjY+K0oVv4AQukF1LRZ\nVDY7Jmsb651KWYl6fltLqJ2en9GnYJfJWkEpkl1INDXL0fRTsuJ/z2T0/JjhWmd6fsxkLabn23Y0\naT0/xWPsk57vVLhKTs+PafHJ6Pmw90pZHfV82c9/4V3p+d39sNhLx6FDCkHLOwB1InKViJhuuwqo\n68mOaTQazWeFiCTVeiPJDvpfBS4FdgDbcQzTdHBXo9Ecfri/AJNpvZFkZ+9sBi7o8kCNRqPp5QhO\nDYfDlb0O+iJyl1Lq1yLyR5x5+e1QSn2rx3qWQP3yNSww+vDjR6/gwUk30mzZfP+hL/LJmXdx3d2v\nUr1iLqPO/BLP33E8pf/9Ff/83n/4uDHItKJ0vvn31/BXb6J49FQuuvgY7jtjKKn/+xMLfvkys1fX\nUhOyGZLh48QpZSz+7UzeX1dPVdAix2twTF4aR5wzhEGXnYcx5WKWNpk8+8lW3ltSxYQJfbjILZpS\n1LqFyCezqX5vEVULNlL1aR3r/WGqQxYBWzG6KJ3cQDVsWU5g9cdxPb9ufQM76wPsCNpxPT8cVbSl\n5lPbalHZHGJLU5CNda1xPd/fGKS1OUTAHyLU0kxmn5wEPb8AI7cYM6/I0fPTclBpOdgpmbRFHK08\nUc83vT532YvpS8Pw+jA9PmfZ46OxLUwgbBMIWu2Kplhhm6itsN25+nasiIqr5ScWTUnzmfjM2LrT\n9kXPB9rp+V5zl37fUc83jeT1fOhcz+8uLT/x+jG0nt976K3STTJ0Je/ErBc+xCl72LFpNBrNYYWT\nkdt98o6InCUia0RkvYjc3cn+FBF53t2/UEQGJuz7vrt9jYic2R3vb69P+kqpGe5im1LqxQ4dvaQ7\nOqDRaDSHGt31nO/WE3kEp4jUNmCxiEzvUOD8eqBBKTVURC4HHgAuE5HRwOXAEThT5d8SkeFKqc5/\nuiZJsoHc7ye5TaPRaHo5jlyYTEuCScB6pVSFUioMPAdc2OGYC4Fn3OWXgFPF0ZcuBJ5TSoWUUhuB\n9exjLZLO6ErTPxs4BygTkT8k7MoGrAO9uUaj0Rxy7FviVaGIfJiw/rhS6vGE9TJga8L6NmByh2vE\nj1FKWSLSBBS42xd0OLcs6Z7tga5m71Th6PkX0F7DbwHuONCbJ0s4qvjpa3fzO+/J+HiJH7xwG8/2\nvYi77/oHzdvWcvQlV/LKzcdi//7bPPGbOWxoDXN+v2xOeeRrXP3T5ZQdcw7XXTKGu44vJ/iPnzH3\ngdd5a0sTfivKkdkpTJ02gFHf+BK/uOgBakI2RSkmk/PTGXnxKPp/6ULUpIt4v6qN5z7ezKIlVVSv\nq+C+yy5hUlkWuXVrCX30Ftvnfkjlgi1sq2hkvT9MbdgmHFWYAnn+rUQ3LqVt5RLqVlZQu6qahopG\ndjQG2RHclZRlu6Hy6jYniLupMcDmujYqavxU1QfiQdxgW5hQSzORtibSRxeQUVqAtyBmslYEmQVx\nkzXbm05rOEpbJLorIcswMb1OAlZipSyPG8CNJWn5gxbhsN1pENcK29i2k5wVtaP43ACuz2OQ7jPb\nJWUlBnF9HqNdEHdX0HZXEDcx8BqN2kkHcTt78tpTEDdGskHcfQ266iBu70WUQrr43CRQq5Sa2JP9\n6W660vSXAktF5F9KKf1kr9FoPheIinbXpSqB/gnr/dxtnR2zTUQ8QA5O8msy5+4ze9X0ReQFd/ET\nEVmW0JaLyLIDvblGo9EceihQ0eRa1ywGhonIIBHx4QRmp3c4Zjpwjbv8JWC2Ukq52y93Z/cMAoYB\niw703XUl79zmvp53oDfSaDSaXoPaLS1pPy+jLBG5BZgFmMBTSqmVInIf8KFSajrwV+AfIrIeqMf5\nYsA97gVgFU4M9eYDnbkDXcs7293FWiCglIqKyHBgJPD6gd48WfocMYgrq8Yy8y8P41/0ON9dV8hf\n73qMqBXmrK9fy/OXj6Li1iv497Mr8VtRvjypL1P+cBeLS05g6EnzuevKcXy5XLHz17fzwaPvM7e2\nDYCpBWkcc9EIhtxwLY2jzqAm9Ev6p3mZNCCbkV8cR58vXkLr8JOYXdHIcx9uZcWyanZu+BT/jk2c\nNCCH1K0f0brgTSrnLqFqURUbtzWzNWBRn6Dn53hN7E8X0rJiKXUrNlK3ppaGikYq/WFqQk5SVsDe\npef7DKGiPsCWpiCbalupqPFT3RCgtTlEW1OINn+ISGsT4bYmrICfzLIivIUlGG7RFDJyiabmEE3N\nJmKm0Ba2aY1EaYuoPer5iSZrZoqj63t8XkIhCyscK5Ziu8lYTgGVRD3ftqwELd/Yq57vSzRcS9Dz\nOyZkRRM0Va9pYAhd6vkdJf1k9PyuDNYOVHvv7HSt5x/iKJXsU3ySl1MzgZkdtt2bsBwEOp0Cr5T6\nBfCLbusMyU/ZnAukikgZ8AbwFeDp7uyIRqPRHCqIiibVeiPJDvqilGoDLgYeVUpdgpMwoNFoNIcZ\nCqJWcq0XkqyfvojIFOBKnOwxcPQpjUajObxQdKu8c6iR7KB/O04G7itucGEwMKfnutWe1XU2y/74\nF8qnnMeps4QF//4TmaUDueP2i7l7sJ/5p5/Di4uqyPeZfPWSUYz+9QP8uyaPX/1hPo/ePIUTqGDt\n93/JnJc+ZWlTkByvwQmFGYz96iTKrvs6FdmjeHreZkZlpTDxqGJGXDqJvPOvZHvOcP63cifPLdrK\nplU7qa9YQVtdFVErjG/V29TPm03l+6vY/tEO1te2URW0aIrY2MrR5nO8Bn1TvdQvXEjdik3Ur2+g\nbnMTlQGnAHpTxNH+E/X8TI/B2rpWKna2srmulbqGAG3NIWd+fmuQcEs9kaAfK+DHDgfxFg/BLCjF\nzCuOF0tRaTkE8dAWjtIaiRKworSErLihWuLcfEe/T2uv57vmaZGQHZ+P72j6Kl5AJabpq6hN1ArH\n9fw0n6ddwZSYjm8aspumD13r+cq22+n5Hefqwy4930hQt7vS82PnQXJ6/v74b/X03PzO7qHpDhRE\nP+eDvlLqXeBdEckUkUylVAVwUBw2NRqN5mDTW/X6ZEi2MPoYEfkEWAmsEpGPRERr+hqN5vCk++bp\nH3IkK+/8Bfi2UmoOgIicDDwBHNdD/dJoNJrPBqUgeRuGXkeyg35GbMAHUEq9IyIZPdQnjUaj+Uw5\nnOWdZAf9ChG5B/iHu34VUNEzXdqdQFMDU+/4Cm/cOoWcKTdRPuU8Hv/2CUz59AVeOfZR3trZytic\nVC78zjTyvvMQ3521nhdfeovqFXM59pxaFv7yad78oJKqoEXfVA8nH1XM2BtPIf2CG5nXksHjs9aw\naOE2nj99IMMvPxXvSZfyqZ3Pyx9V8vribVSuraJpy2oCDTsASMnKp/q16VR+sI4dS3eypsWpkuW3\nnA9KmikU+jyUpXnoU5DGjoXrqFvXwM6drXGDtaaIUyULnNJssSButsdkZWUzm2tbaW4M0tYcoq0l\nRKjVT6S1qV0Q1woF8JSUY+QUxg3WoilZtFmKtohNqxUlEInSFLRoClm7BXHjAVy3apbHl4JhGnh8\nJh6viZVgtma7wdt2iVlW2AnkRsJOANdNyOoYxI0308AQ2WuVrFgQV9kJyVmGsdeErFgAVyS5AG7i\n/boK4u5vAaVkgrgHUp1JB3B7ku5NzjrU2JfC6EXAf4CXgUJ3m0aj0Rx+fF41fRFJBb4BDAWWA3cq\npSIHo2MajUbzmdDNNgyHGl3JO88AEeA94GxgFM6cfY1GozksET7fmv5opdQYABH5K91g67k/9O1X\nypwzIrw5cjLH3fYHXr3hGBp+8nUefHQBVcEIXxiWz0l/upmKoy7hy39eyLJZ7+Kv3kRO+Sjeuu4h\n5uzwE7CjTMhNZcpZgxl+w+WEj72Ef6+u5al3lrPh4w00bF7B6N/ciD3+XGZvbuaFTzbw4ZLtVK9b\nR3PVBqygH8PjIzWnkOx+I1g341G2bmpkY2ukXcGUTI9BSYqj5xeXZZE/LJ+qRVVUNYfYEbRpttoX\nTDEF0kyDTI9Bntck32cws6oZf1OQQEuYgD9EqKUxbrBmh4NY4QDRSJioFUby+2CnuQZrnjTawlEC\nlqI1EqU1bNMUsmgKRvCHbUxf6u56foLBmmkaeLwmhsfA4zUIh6w9GqzFtPxYclaaz9yjwZppCD7T\nwGsIhiF7LZgC7fV8FbW71PPjunySQneinr+3gimJknuyOmhnHG56/gF0vZegwD58Z+909VmOSzn7\nWkRFRPqLyBwRWSUiK0XkNnd7voi8KSLr3Ne8/ei3RqPR9AwxG4bDVNPvatAfKyLNbmsBjooti0hz\nF+daODGA0cCxwM1udfe7gbeVUsOAt911jUajOWQ4nF02u/LT329TNdeLf7u73CIiq3GK+l4InOwe\n9gzwDvC9/b2PRqPRdC+f70ButyAiA4HxwEKgJKE4yw6gZA/n3AjcCFCWk8kDU26mNmzx9pmKd487\nmZdX7KQkxcOtXx3HkJ//jqc2e3jwF7PZsuhNAMqnnMcl545kxnmPkO8zOa08j6OuO5aSq77OurTB\nPP7mBt6ct5mqFUvwV29CRW22Dz+TmUt28MKCLWz5tIb6imW01VWhojae1EwyivuTXz6M0oG5rHil\nnq2BSFyf9xlCvs+kJMVDeZaPvMG5FIwoJG94f96bVRE3WAvYuyry7Jqbb5Dj6vk5WSk01rQS8Ifj\nBmvhtibsUAAr2IrtavkxPdzOKkKlZBFQJoEEg7XGgIU/7MzP94csmkNWgn7fucGax2vi8Rlxbb+1\nObTb3PyYhh/T8+OavtfcTc+Pmax5DQNTnGIoXkO6NFiLL7vbvYaxW/HzRD3fkOR05o5z+JMxWDuU\ntPx9v3/33uvw1/ITOIwH/QP5TCeFiGTizO2/XSnVThJy60B2WpdMKfW4UmqiUmpiQUZaT3dTo9Fo\nHGI2DMm0XkiPDvoi4sUZ8P+llPqPu7laRPq4+/sAO3uyDxqNRrNvKJQVSaodCMlMahGRcSLygTsZ\nZpmIXJaw72kR2SgiS9w2Lpn79tigL87v2L8Cq5VSDybsSqz8fg3w357qg0aj0ewzioP1pJ/MpJY2\n4Gql1BHAWcDvRSQ3Yf93lVLj3LYkmZv2pKY/FaeW7nIRiXXmB8CvgBdE5HpgM3BpD/ZBo9Fo9gmF\nahdb6kG6nNSilFqbsFwlIjtxLHEa9/emPTboK6XeZ895JKfuy7Wqqpooys3n5t9fwoOTbmRDa5jz\n+2Vzyh+vo3Lq1zj7+aUsmfU+zdvWktVnCKOnHcePLjiCU7ObeCw7hanTBjDqG19CnXw1L66p4y+v\nLmHDks3Urf+YSGsTntRMcvoN51dzNrDgkyp2rN1A8/YNRFqbEMMkvaAvWX2GUjywlKFD8jl5ZDGr\n/eF4QlaO14gbrJX2LrxafAAAH7lJREFUySR/WB75w/uSN2oAKYNGsjUwY48JWdkeg3yfSWGKh/TC\nNDJKMmhpCBBqaSbS1kS4tWm3hKzEgKSVlk9rJEpbvEKWTUvYoilo4Q/bNIUi+IMWTW0RvKmZTnKW\nG8TtLCErFtA1PYZbLWvPCVnxQG7UjlfO2lNCViyY6zGNpBKyEukqIatj1azO6MyIbV8SsvY1APtZ\nBnG7O4ALn7cgLvtSOatQRD5MWH9cKfV4kucmNaklhohMAnzAhoTNvxCRe3F/KSilQl3d9KDM3tFo\nNJrewz756dcqpSbuaaeIvAWUdrLrh+3uqJQSkU4ntbjX+f/2zjw8jrvM85+3qrullmTrlixbjuX4\nNgkJORxCBiYkgQSWHJsNIYFhmF0yHpb7AYYkZGFgnp1nAzObsCwsYG52MjAQyEOAgElCjuUIwUns\nxI7t2PER35Zlqa2jpe7q+u0f9etWtdwttXxIavf7eZ56uupX1VX1s1tvV3/fq4OgyvF7jMmFFt1J\n8GURA9YQ/Er4x4luWI2+oihKGGNO2kk7eipzVbF9InJIRDqMMQfGC2oRkdnAL4G7jDFPhc6d/ZUw\nIiLfAT5Ryj2d9pBNRVGU8sLkpMuJlpNkwqAWEYkBDwDfN8bcP2ZfNgpSgBuAjaVctCye9FsbqvnP\nm3/JFzZliHE/n/zo6+j8zD3cs76fb3z6N+x75mGcSIyz33A9775uBR+4pJPqJ7/H+i/fzzs++1Ya\nb17NizKXr/5iK0/+4RUOvPgcg917AKhr76J50bmc/ao2fvXrLfTteoFk7yGMnyFaW8+s9i4aOrvo\nWNjIZctauWxhE69qq2WDb4i7QmPUZU51hPn1VTQtaaJpcTONKxZQt3gx0a4V+M0LSKRH9cG4K8Td\nUS2/KeYyq76KurZaalri1HXMZqjnUF6BtbEJWWF6hzM5PT/bLGXAavqDqUDL7xtKMzDi4cbieQlZ\nkZgbaPqhhKywtp/T9EPNUsIJWX7owx8Pafqu1fCjblAkbVTXl5zePFFCVng76oY0/AIJWWGNfywT\n/WGeai2/EOOdo9QicaWiCVmngGz0zumnYFCLiFwEvM8Yc5sdewPQLCJ/Y9/3NzZS5z4RaSXwna4n\nKIM/IWVh9BVFUaYOMxlH7olfxZgeCgS1GGPWAbfZ9X8F/rXI+684keuq0VcURQljmKqQzWlBjb6i\nKEoek4reKTvKwuh7nQu54J4tbH/iIQaeXsMj7krefs+zvPTEI6QGE7Qufy2XvelcPveW5SzpeZad\nd/w3nvnRRp46muQT9z3Ivc8f4P4nnmb3hhdJ7H2JTCpJdX0rDV3nMH/5PK56zVzetqKdN3zv38ik\nkrixODXNc5nduYw5XY2cv7SF1y9q5oK5s+maHSV6aOtocbWaCM0L6mlZ1kzD0k4ali0k2rUc6ViE\n19BJbyb4J445QtwVat1RLb+xNkq8pYa6thpq22uJtzVSO6eJ5K8O5hqfF9PyxXERx6VveDQuP6vn\n948EWv7AcLA+MJymf9gjWls/Goefa4DuWB1/jL4fcfBS6eD6mfy4fONnyGS37RNRVtPPavhR2wQ9\n6gY6ftQRXKvplxKbH94eW1xt7Bgcr42X4mQbq+ePp+WfqPZeTM9XLX8Gcwqjd2YiZWH0FUVRpg59\n0lcURakcpi56Z1pQo68oihLCYHJ9nM9E1OgriqKE0Sf96eflXQeJPvZzOi9+M1euFZ5f+zUGDu2i\n/qwVXHTjdXz22pVcVnWIQ1/7e379zT/y+8ODHE1lmFMd4Z3f/jM71u/i6M4NpAcTRGvraew6h7nL\nz+ay8+dy7TlzuKijltmHX8T4mZwDt21BG0sXNfGXy9q4pLOeRY1VxHt34a/bwLGN6zmvvoq2ebOC\nhCxbXC3WtRx33lIyjZ0cc2roHvTYe2yIukhQXK3RdsdqjEWoba+hpqWG2rYaatrqqe1oJt7aSLS1\nndRPthcsrpZFHBcnEkMclwMDI/Tbzlj9qVEHbl8yzcBwmqFUhoFhj1QqQ6wqkpeAlUvOirq4EcFx\nHWKhJKvMSLJgcbWcQzcTSs6KugWLq2U7ZjkiufVSHbhZ3FBnq3BxtTzHLqPOzFIzJUtJyKo0By5U\nuBMXAkduOjXdd3HaKAujryiKMnVMTXLWdKFGX1EUZSwq7yiKolQIxpyKYmozlrIw+pHqWm7/7x/l\njr/sov7S9zOrYxGrbnk3d12/kqsaBjj6/c/x6Dd/z+9eSdA9kqG1yuVtHbNYfuMK/vmBn+UapTQv\nvoA5Sxdx8XkdXHduB5d2zqLh6DZG1j7MzifX0br8GlrOamfpkmYuX97GqnkNLGqMUde/D/+55xjc\n8jxHnt/OkRcPsez18/MapbidgZafcOvoTnrsOzbIrr4ku3uGmFsdOa5RSlbLDxKymok2t+A2tuE2\ntuIl10+o5bvRoBnKgf6RoMBaMk1iKEjCGhjx6B9O57R8L53BS/vE4tHjGqVEos5xWn5VxCEei5BJ\nJSfU8rP3WRVxxtXys4labhHdvdgfmfEzE2r5MNpgZbJ/rKVq+Scrc6uWX15o9I6iKEqlYAwmo0Zf\nURSlIjDG4Ke96b6N04YafUVRlDAGfdKfbs6ZP5sPb/sWj//db3jdR77EZ65dyRviRzj8nc/yyDf/\nwP87MMDRVKDlX9s5mxU3nUPnTTfgX3At5orbaVl6MR1LF3Kpjcu/eG4d9Ue2MPLrR9j5xDr2/3kv\nu1/u5fX3fDwXl7+woYraxCv4zz3HwOZAy+/Z2s3RbUfZf2yEm794C1WLVubi8vucGrqHPPYeG+SV\nRJId3YPs7hlk75EhPj6r6jgtPxeX39yC2zwHt7ENahvx4/UFi6uN1fKdSBQnEuOV3qGgsNqwRyKZ\nyovLT48Een4m4+OlMlTXRseNyw+am9tt1zmuUUohLT+rfVa7TtG4fEeCWPtsg/Pw/MbT8rNk/QDj\nafkw+TZw2eOnU8s/kfOfDj1fyUeNvqIoSoVgjMHXevqKoiiVw5kcvaON0RVFUcLY6J1SlpNBRJpE\n5GER2WZfG4sclxGR9XZ5MDS+UET+JCLbReTfbRP1CVGjryiKEiIbvVPKcpLcATxqjFkCPGq3C5E0\nxpxvl+tC458H7jXGLAZ6gfeWctGykHeOPr+Fz3y4l5gjPHq1YecXP8BPbGesZMbQVRPlqmXNLL/5\nQtpvfAd981fx0x29/PC+Dbzm+htynbHOba0muvNPDPzoEbY+sYH9zxxkx/5+9iTTHE1l+MzVy3Kd\nsdK/f4beTRvp2bSTni099O7oY89Qmu4Rj2OeT/yKt5Np6KQ7E6F7yGN3Xz97Ekl2WgfuwZ4hBo+N\nMHhshDnnt+V1xoq3NRJpbMVpbCPSPAe/pgG/ahZ+vJ6UE3xZZztjiePiRGM41pmbdeC6VXHcSIy9\nvclcZ6yBYS9IxEr5NiHLOnI9g+/51M6uzuuMFY+5VFknbtiBmx3zUslccbRCDtzR9aDgWrYz1miX\nrHwHbuDcHb8oWsGktCKF1cY6cIsVOStGMQduobNMNrnqdDhwlanDnxpH7vXA5Xb9e8DjwO2lvFGC\nD+8VwDtD7/8s8NWJ3qtP+oqiKGFsyGaJ8k6LiKwLLasncaV2Y8wBu34QaC9yXLU991MicoMdawb6\njDHZnxt7gXmlXLQsnvQVRVGmjMll5B4xxlxUbKeIPALMKbDrrvxLGiMipshpFhhj9onI2cBvReQF\nIFHqDY5Fjb6iKEoIw6mL3jHGXFVsn4gcEpEOY8wBEekADhc5xz77ukNEHgdeA/wEaBCRiH3a7wT2\nlXJPZWH0U77h7Rd0cP7qN3LPqtW8PJgi7grn1Vdz3uvns+zWNxK9/Ba2mWa+s+kgDz34FHu27CPx\nymbW/+hOOv0e/I0/58h3fs++P27j4IbDbB9IsX/YY8AL/nPjrrD44FOkHn+G/S9s58jGPfRs66Wn\ne5B9SY/edIZE2iflB1/Ge6rP4lBPml19A+w6OsSO7kH2Hh0i0TfM4LFhkv0pkv39pAcTdFyymJq2\nRqpamnKJWE59C368Hq96Fn51PUOeYSjlk/Q8q93HENfFDen4TjRGJBYPNP1YHCcaY/eRQUZCRdW8\n0HrG88lkfHz7Wl0bJZan5Y/q+NlCa7HQ4qdTebp99g8hPAbg+xmqIzYhy2r5UcfJ0/HDun6pxday\nuFntfgIt/2R197FvP9VF0lTHLxOMwU9NSRmGB4H3AHfb15+NPcBG9AwZY0ZEpAW4DPiC/WXwGHAT\n8MNi7y+EavqKoihhDPi+X9JyktwNvElEtgFX2W1E5CIR+aY9ZgWwTkQ2AI8BdxtjXrT7bgc+JiLb\nCTT+b5Vy0bJ40lcURZkqDFNTZdMY0wNcWWB8HXCbXf8DcG6R9+8AVk32umr0FUVRwhjy+jifaZSF\n0e9YuYCFax/mK+v3E+N+brmwgxU3X0Trje/icOu5/OTlXn7wwCu8vGkDR17exGD3HnwvhRuL0/Dj\nf2Lr717gwLMH2X5gkP3DQUx+xkDMEVqrXNqrIpxVE2XbF7/MkS099O5KsC/p5WLykxmfjPWrxxwh\n7gq/3HaEHYeDmPwjvUkG+oYZGkgxPJgi1X+U1FACLzlAJjVM8yUX5hqk+DUN+NX1ZKpnkXJiDKZ9\nhgY9kmlDYiRN/0iGaLwuF5PvVlkNP6Tju7F4rhHKscRIwZj8bKE14xsynofvpWiui+Vi8uNRN0/H\ndx3J0/OjTlBwDY6PyYdAx89iMhmqIk7BmPzwdrgRSvhc4xE0UTm+qFohHf9E6pCVGpM/2RyAia6h\nzGSMlmE4EUTk2yJyWEQ2hsZKSjtWFEWZNiYXp192nE5H7neBa8aMlZp2rCiKMi0YY8ikvJKWcuS0\nGX1jzJPA0THD1xOkC2Nfb0BRFGVGYaykOfFSjky1pl9q2jE2nXk1wFkdRQ9TFEU5tWjnrNPDBGnH\nGGPWAGsAauctNZes/haJvS8x8PQa+uav4uEdvfzw8T1s3fQo3dtfZPDwHjKpJG4sTm3rfGZ3LqP9\nrAZ+/KkP5gqqZUyQ6FMfzTpvIzQvqKdlWTMNSzv52b88VtR5WxcRal2HpphLU8zl63/YnSuoVsh5\n640k8b0guSn6qr/Cr64nbQuqDaZ9hoZ9kuk0/SmPxLBHYsRjIOXRP+IRq2vMFVQr5Lx1XYdIzCUS\ndRhIJHPO20wmSMjyM37OeWsymdx9NNVV5RVUG7u4tlhatvOV76WD/4siztvcejg5q4jzNlw0bSIH\n7tj92eSs8Zy3J/KTNexgPZOct9pY6yQxYDJFTVPZM9VGv6S0Y0VRlOnCYKaqyua0MNUZudm0Y5hE\n2rCiKMqUYcD4pqSlHDltT/oi8gOCWtEtIrIX+AeCNOMfich7gd3Azafr+oqiKCeCMZBJaXLWpDHG\n3Fpk13FpxxOR7Osl1n+UeRdeyZVrhd2bH6Jv1wsM9ewPNPPaembNXUTTWYuY09XApUtbuezsZs5t\nq+V/fHrYJmFFmFsdYV5djKYljTQtbqZpxQLqliwm1rUcv6WLDZ/+Ve6acVeIuw6zIw71UZfWKpdZ\n9VXUNMepa69l16b9pAcTeTp+Jp3K6edhXbq/cRGDaUMy6TOUTuVp+AMjHsdGPBJDthHKiEe8cU4u\nKSsSdYnEsjq+bYASdXEiDpGow+FXEqNavr12tlCa8QM937frbbOqRvV7m4wVdRyiruT0fMexr7Yw\n2ng6fpiaqJtXEC2s44/q7lJUbx5P5xeR0SYqofc7Y46ZLMcVXBvnHKe6+JpzioV31fFPIcaopq8o\nilJJ+Gr0FUVRKgQN2VQURakcDOCXqZO2FNToK4qihDFGHbnTzZx57fz0Gx/hvPYa6i99P24sTryx\nnbkXXk37WQ28emkLr1/cwsXzZtM1O0r00FbSL/2C/l9v5Or2WpoX1NO0uJGmFWfRsGwh0a7lSMci\nMg2d9GYidA957O4dpj7q5CVgNdZGibfUUNdWQ217LfG2RmpaG6jpaKb3GxvyErDGOiLFcXPLlp5h\nEsOB4zYxEiRgJYbSDAwH6wPD1ok77OGlM9S1tOQlYDmhpCw3IoFz13bA2r1pb14CVnbJZLczo9Ux\nW2dXHZeAFXUDp23UyXa9Gl3PpFO5+UzU7SrqOHkJWOGKmnnjRd4/Hq712I7nuD1RR2sx5606bisX\no8lZiqIoFYQafUVRlEpCM3IVRVEqhynKyC2lv4iIvFFE1oeWYRG5we77rojsDO07v5TrlsWTfluy\nm6qP3MJvnznI6z72v/OSrzoiw7gHNpPa8hhHf76FbVv2cGRLDz37B9iX9Fj9bx/OJV95DfPoHvLo\nHvTY1TvE7p2j3a96e4f5dFdDLvmqpq2OmrZGauY0EW9twmlsI9I8B6ehFT9ez/C/fD7vHsMavhMN\nOl05kShOJMYfXunNS77KavhDVsP30j5eKpPrdlXfXJNLvsoWWcsmVVVFHOKxSLDtOjzVfzSXfJXV\n8MNdroIleGppqo7mJV+5Y9YdIdD83dHkrCyFNPjwWMTNT75yZFS/DydtFTvXeDjka+/HJVVN6myh\n941zzuOOneS5T7WGH0b1/NOLYcri9LP9Re4WkTvs9u1592LMY8D5EHxJANuB34QO+XtjzP2TuWhZ\nGH1FUZQpwxj8qYneuZ6gVA0E/UUeZ4zRH8NNwK+MMUMnc1GVdxRFUUIYEzzpl7KcJCX3F7HcAvxg\nzNg/icjzInKviFSVclF90lcURRnDJLpitYjIutD2GtsLBAAReQSYU+B9d+Vdb4L+IrYU/bnA2tDw\nnQRfFjGC3iO3A/840Q2XhdHft7ePr+99ibgrPHq1YWTzQxz94VZ6Nu/l5S09dB8c4OBwhiMpjwHP\nJxn6Bt746neysy/J7q1D7Ojeyu4jgyT6hhk8NkyyP8Xw4FCucNpFH76SeHsrbmMrbmNbTr/34/X4\nVbMY8IXBtGEo7eNEYgX1eycaIxILiqU5kRhuVZzHNh8uqt97qaD5SbgJyooL5hKLONTEXGIRN6ff\nZzX9cOOT1GACOF6/D+v6EDRAaYxH8/T7qOPkmp0Uan4ykaYfJuZkG5zk6/fZn5KFGqCUiht609i3\nn0w8fbH3qmRe4ZhJPcUfMcZcVPxU5qpi+0RkMv1FbgYeMMakQ+fO/koYEZHvAJ8o5YZV3lEURQlj\n4/RLWU6SyfQXuZUx0o79okCCJ6obgI2lXLQsnvQVRVGmCsOUFVwr2F9ERC4C3meMuc1udwHzgSfG\nvP8+EWkl+HG6HnhfKRdVo68oihLGGDKp02/0jTE9FOgvYoxZB9wW2t4FzCtw3BUncl01+oqiKCGM\nAd9oGYZppXV2FZ/8L6+jaUUX96xaTW86w4Dnk7IZca4EjsS6iMPc6ihNMYfWqgg1TXFu+z9/ZKh/\nhJHBgcBhO5jAGx7E91J4I8lcdymAWX91N5nq2QykfQbTPknPJ5n2SRz1SIz0MzBiO16NeMyau8g6\ncGO4sbh14FaFulq5ueJor+zoJWMdtV4qgzEm1+lqbJcr42c4Z96KvO5WuSVUJC3qOLgC3vAgkO+w\nhcJdrhrj0YIO27GF0UpJojq+4Fr2HPkO22KdriaDUNjpeiLdssaet1S0YFplkVGjryiKUhkY4Ayu\nt6ZGX1EUZSz6pK8oilIh+IacdHwmUhZG3z/rbJ766y+w8+gQMe5nUW2UppjLrOYaalri1LbXUts2\ni5o5zdS0NRJrbsJt7sBtbGXrbT/NafZhcsXRbAKVG4lx/84UiZGDgXZvC6QlkmmSKY/+YY9kKMFq\nzrKVOc0+2/DEce22bXCSTaZ6cu3zeZp9oQJp4WSq5R2zcpp9xA1eAy1/dD1bLC3rlxhLobHZVZE8\nzT5bIG1sg5Osfj2ZwmgRV4o2OTnZhiTumBOc6gYnwTlVs1dGUXlHURSlQjAYlXcURVEqBXXkKoqi\nVBhq9KeZbbsP8bcf+p/46RQDT6+B2sagCFr1bNKROENpn6Rn6Ev77EtlSIx4JIbTDKQyxBvbjyuE\n5lYFr5FYNNDjbWz9vQ++aIuh5RdA8zM+Gc8L9HgbV3/1tRfkYufHFkHLxdi7DlFHeOj7O/MKoYW1\n8kJx9UuaascthBZuVpJJJUv6NzR+hrpYoLqPLYIGhePqJ0OsBN39ROPqww1ZTiWT0fFVo68cjNHo\nHUVRlIrBoNE7iqIoFYNq+oqiKBWGyjuKoigVQqDpT/ddnD7Kwui7sWraVl6GG3G4cq3gpY7ipbtt\nolSGjGfwPT/Xjcr4hozn4Xsp3vzO/2Cdqy7xqJvXfWpsQbNP/8N3Q0lSfsHuU1luvfA6HOE4R2sh\nx+tw4kjufaUkPJ1VH7S6LKX71GQSqGqjwZkK+SRPNuEp6uaf4FT6Pd3T5EVV56xSDH3SVxRFqRAM\nMCUtVKYJNfqKoighDEajdxRFUSqFIHpHjf60cs6CJn7/pbcBUH/p+yf13u9+7e0lH/ux7j0lH3vZ\n/FklH1uo4Nt4tNWenv+WmuiJtjGZmMjpqIJmUe1dmVLOcEfu6bMC4yAi14jIVhHZLiJ3TMc9KIqi\nFCL7pF/KcjKIyNtFZJOI+LYZerHjCtpLEVkoIn+y4/8uIrFSrjvlRl9EXOArwFuAlcCtIrJyqu9D\nURSlGBlT2nKSbARuBJ4sdsAE9vLzwL3GmMVAL/DeUi46HU/6q4DtxpgdxpgU8EPg+mm4D0VRlOPw\nCcowlLKcDMaYzcaYrRMcVtBeShC/fQVwvz3ue8ANpVxXzBQ7LETkJuAaY8xtdvvdwCXGmA+OOW41\nsNpunkPwrXim0AIcmfCo8uFMmw+ceXOqpPksMMa0nuiJReTX9vylUA0Mh7bXGGPWTPJ6jwOfMMas\nK7CvoL0EPgs8ZZ/yEZH5wK+MMedMdL0Z68i1/3BrAERknTGmqOZVbuh8Zj5n2px0PqVjjLnmVJ1L\nRB4B5hTYdZcx5men6jqTYTqM/j5gfmi7044piqKcURhjrjrJUxSzlz1Ag4hEjDEek7Cj06Hp/xlY\nYj3PMeAW4MFpuA9FUZSZTkF7aQJd/jHgJnvce4CSfjlMudG330ofBNYCm4EfGWM2TfC2SWlkZYDO\nZ+Zzps1J5zPDEJH/KCJ7gUuBX4rIWjs+V0Qeggnt5e3Ax0RkO9AMfKuk6061I1dRFEWZPqYlOUtR\nFEWZHtToK4qiVBAz2uiXa7kGEfm2iBwWkY2hsSYReVhEttnXRjsuIvIlO8fnReSC6bvzwojIfBF5\nTERetGnjH7HjZTknEakWkadFZIOdz+fseMG0dhGpstvb7f6u6bz/YoiIKyLPicgv7Ha5z2eXiLwg\nIutFZJ0dK8vP3Exixhr9Mi/X8F1gbKzvHcCjxpglwKN2G4L5LbHLauCrU3SPk8EDPm6MWQm8FviA\n/b8o1zmNAFcYY84DzgeuEZHXUjyt/b1Arx2/1x43E/kIgbMvS7nPB+CNxpjzQzH55fqZmzkYY2bk\nQuDRXhvavhO4c7rvaxL33wVsDG1vBTrsegew1a5/Hbi10HEzdSEIDXvTmTAnoAZ4liDL8QgQseO5\nzx9B5MSldj1ij5Ppvvcx8+gkMIJXAL8gaF5WtvOx97YLaBkzVvafueleZuyTPjAPCNc63mvHypV2\nY8wBu34QaLfrZTVPKwW8BvgTZTwnK4WsBw4DDwMvA30mCJGD/HvOzcfuTxCEyM0kvgh8ktGmT82U\n93wgKHj5GxF5xpZlgTL+zM0UZmwZhjMZY4wRkbKLlRWROuAnwEeNMcckVOi+3OZkjMkA54tIA/AA\nsHyab+mEEZG3AYeNMc+IyOXTfT+nkL8wxuwTkTbgYRHZEt5Zbp+5mcJMftI/08o1HBKRDgD7etiO\nl8U8RSRKYPDvM8b81A6X9ZwAjDF9BJmNl2LT2u2u8D3n5mP31xOkwc8ULgOuE5FdBFUYrwD+F+U7\nHwCMMfvs62GCL+ZVnAGfuelmJhv9M61cw4MEqdKQnzL9IPDXNvrgtUAi9PN1RiDBI/23gM3GmHtC\nu8pyTiLSap/wEZE4gX9iM8XT2sPzvAn4rbHC8UzAGHOnMabTGNNF8HfyW2PMuyjT+QCISK2IzMqu\nA28mqLRblp+5GcV0OxXGW4C3Ai8R6K13Tff9TOK+fwAcANIE2uJ7CTTTR4FtwCNAkz1WCKKUXgZe\nAC6a7vsvMJ+/INBXnwfW2+Wt5Ton4NXAc3Y+G4HP2PGzgaeB7cCPgSo7Xm23t9v9Z0/3HMaZ2+XA\nL8p9PvbeN9hlU/bvv1w/czNp0TIMiqIoFcRMlncURVGUU4wafUVRlApCjb6iKEoFoUZfURSlglCj\nryiKUkGo0VemHRHJ2EqKm2zly4+LyAl/NkXkU6H1LglVO1WUSkeNvjITSJqgkuKrCBKl3gL8w0mc\n71MTH6IolYkafWVGYYKU+9XAB212pSsi/ywif7Z10v8OQEQuF5EnReSXEvRc+JqIOCJyNxC3vxzu\ns6d1ReQb9pfEb2wWrqJUJGr0lRmHMWYH4AJtBNnMCWPMxcDFwN+KyEJ76CrgQwT9FhYBNxpj7mD0\nl8O77HFLgK/YXxJ9wH+autkoysxCjb4y03kzQU2V9QTlnJsJjDjA08aYHSaomPkDgnIRhdhpjFlv\n158h6HWgKBWJllZWZhwicjaQIaigKMCHjDFrxxxzOUE9oDDFaoqMhNYzgMo7SsWiT/rKjEJEWoGv\nAV82QWGotcB/taWdEZGltuoiwCpbhdUB3gH8zo6ns8cripKPPukrM4G4lW+iBP14/y+QLeH8TQI5\n5llb4rkbuMHu+zPwZWAxQRnhB+z4GuB5EXkWuGsqJqAo5YJW2VTKEivvfMIY87bpvhdFKSdU3lEU\nRakg9ElfURSlgtAnfUVRlApCjb6iKEoFoUZfURSlglCjryiKUkGo0VcURakg/j+7fyjNRp+DjgAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i65Om8hD9Zxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRiHUdz39Zxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgeW4C3oExgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HiVIAXyEy5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IAKZCvaE0gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1jGveflE2jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf9ttwGRE3wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "28d5e579-2360-40d8-9ff1-391613699461",
        "id": "XpnYSgcu17j7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(tf.random.uniform((64, 43, 512)), False, None)\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzu9k0srFGy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvr8kY2mFIpJ",
        "colab_type": "code",
        "outputId": "b8b316c5-258f-4502-dc76-fdd3e3022856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "448yE6whFLgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylfpvCwNFNYi",
        "colab_type": "code",
        "outputId": "ec618287-9bd7-4222-8c26-ab2a74d40370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 62, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrIo-7tHFQSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAveYszVFRvJ",
        "colab_type": "code",
        "outputId": "d54842c6-40c4-4fe3-dd74-b1c28b513fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input, \n",
        "                              enc_output=sample_encoder_output, \n",
        "                              training=False,\n",
        "                              look_ahead_mask=None, \n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc8oWZd4FT78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwOFxB5CFVw6",
        "colab_type": "code",
        "outputId": "c9433ec5-4472-4018-97b7-50398347e05b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
        "    input_vocab_size=8500, target_vocab_size=8000, \n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
        "                               enc_padding_mask=None, \n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 36, 8000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmFpwFVzFYtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = len(inp_lang.word_index)+1\n",
        "target_vocab_size = len(targ_lang.word_index)+1\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhgVW3d3FdvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkntDp1PGDSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVtuFWxFGEw1",
        "colab_type": "code",
        "outputId": "0e01c4ae-8f89-4995-ac4b-fb38c4f2fa11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaAV0BPqGIry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaXpPuq0GKsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik752JrQGMW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YO1OiMZGOIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfH_CDj8GSbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by \n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOtnWDKEGUO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5eca2cfb-c204-46a6-a1ef-8aff54ecf74e"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGai1h9BGWHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNCGSCfvGZT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_0GEaOCGcK_",
        "colab_type": "code",
        "outputId": "5f1c49a2-063a-4ac1-ddf4-f40e2efd45dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(dataset):\n",
        "    train_step(inp, tar)\n",
        "  \n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
        "  "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.8939 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 2.0424 Accuracy 0.0001\n",
            "Epoch 1 Batch 100 Loss 2.0074 Accuracy 0.0037\n",
            "Epoch 1 Loss 1.9897 Accuracy 0.0051\n",
            "Time taken for 1 epoch: 485.8978748321533 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.0500 Accuracy 0.0089\n",
            "Epoch 2 Batch 50 Loss 1.8832 Accuracy 0.0092\n",
            "Epoch 2 Batch 100 Loss 1.8366 Accuracy 0.0097\n",
            "Epoch 2 Loss 1.8018 Accuracy 0.0103\n",
            "Time taken for 1 epoch: 468.92828726768494 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.4343 Accuracy 0.0117\n",
            "Epoch 3 Batch 50 Loss 1.5961 Accuracy 0.0174\n",
            "Epoch 3 Batch 100 Loss 1.5448 Accuracy 0.0188\n",
            "Epoch 3 Loss 1.5138 Accuracy 0.0193\n",
            "Time taken for 1 epoch: 469.7583894729614 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.2693 Accuracy 0.0201\n",
            "Epoch 4 Batch 50 Loss 1.3602 Accuracy 0.0226\n",
            "Epoch 4 Batch 100 Loss 1.3542 Accuracy 0.0233\n",
            "Epoch 4 Loss 1.3461 Accuracy 0.0235\n",
            "Time taken for 1 epoch: 473.67414808273315 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.1517 Accuracy 0.0225\n",
            "Epoch 5 Batch 50 Loss 1.2920 Accuracy 0.0272\n",
            "Epoch 5 Batch 100 Loss 1.2791 Accuracy 0.0279\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
            "Epoch 5 Loss 1.2626 Accuracy 0.0283\n",
            "Time taken for 1 epoch: 471.41708731651306 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.1208 Accuracy 0.0306\n",
            "Epoch 6 Batch 50 Loss 1.2063 Accuracy 0.0317\n",
            "Epoch 6 Batch 100 Loss 1.1967 Accuracy 0.0327\n",
            "Epoch 6 Loss 1.1809 Accuracy 0.0330\n",
            "Time taken for 1 epoch: 472.090594291687 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.1939 Accuracy 0.0388\n",
            "Epoch 7 Batch 50 Loss 1.1224 Accuracy 0.0369\n",
            "Epoch 7 Batch 100 Loss 1.1261 Accuracy 0.0375\n",
            "Epoch 7 Loss 1.1170 Accuracy 0.0381\n",
            "Time taken for 1 epoch: 470.7481575012207 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.0888 Accuracy 0.0385\n",
            "Epoch 8 Batch 50 Loss 1.0647 Accuracy 0.0422\n",
            "Epoch 8 Batch 100 Loss 1.0624 Accuracy 0.0429\n",
            "Epoch 8 Loss 1.0597 Accuracy 0.0432\n",
            "Time taken for 1 epoch: 470.41295409202576 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.0196 Accuracy 0.0428\n",
            "Epoch 9 Batch 50 Loss 1.0273 Accuracy 0.0465\n",
            "Epoch 9 Batch 100 Loss 1.0203 Accuracy 0.0469\n",
            "Epoch 9 Loss 1.0128 Accuracy 0.0468\n",
            "Time taken for 1 epoch: 469.8212637901306 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.9111 Accuracy 0.0441\n",
            "Epoch 10 Batch 50 Loss 0.9788 Accuracy 0.0495\n",
            "Epoch 10 Batch 100 Loss 0.9745 Accuracy 0.0497\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
            "Epoch 10 Loss 0.9738 Accuracy 0.0498\n",
            "Time taken for 1 epoch: 471.4520072937012 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm2u8_Ef2fJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "  start_token = input_tensor_train[0][0]\n",
        "  end_token = 3\n",
        "\n",
        "  # Add the start and end token\n",
        "  inp_sentence, y = tokenize(inp_sentence)\n",
        "  inp_sentence = tf.squeeze(inp_sentence)\n",
        "  inp_sentence = inp_sentence.numpy()\n",
        "  inp_sentence = inp_sentence.tolist()\n",
        "  inp_sentence.append(end_token)\n",
        "  inp_sentence.insert(0, start_token)\n",
        "\n",
        "  #inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
        "  \n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "  decoder_input = [target_tensor_train[0][0]]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "  \n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "   \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "  \n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        " \n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == end_token:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "    \n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jN3DnYF2mqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence, plot=''):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  \n",
        "  result = result.numpy()\n",
        "  transl = \"\"\n",
        "  for ele in result:\n",
        "    transl += targ_lang.index_word[ele] + ' '\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(transl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTSqtBZM2o7F",
        "colab_type": "code",
        "outputId": "599effcc-76ee-4bfe-f6db-31799a1835c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "translate(\"i agree that we need an ambitious social agenda which will include combating poverty and social exclusion\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: i agree that we need an ambitious social agenda which will include combating poverty and social exclusion\n",
            "Predicted translation: <start> il est la commission et la commission a la commission et la commission et la commission est la commission , et la commission est la commission , mais il est la commission et la commission a la commission et la \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}